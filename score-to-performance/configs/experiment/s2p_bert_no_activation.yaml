# @package _global_

# to execute this experiment run:
# python train.py experiment=s2p_bert

defaults:
  - override /data: expression
  - override /model: s2p
  - override /callbacks: default
  - override /trainer: ddp
  - override /logger: csv
# all parameters below will be merged with parameters from default configurations set above
# this allows you to overwrite only specified parameters

task_name: "s2p_bert_no_activation"

tags: ["no_activation"]

data:
  batch_size: 512
  # output_features: ["Pitch", "Velocity", "Duration", "IOI", "Position", "Bar"]

trainer:
  min_epochs: 10
  max_epochs: 8000
  accelerator: gpu
  devices: 2
  num_nodes: 1
  strategy: ddp_find_unused_parameters_true
  sync_batchnorm: True

model:
  penalty_outliers: False
  dynamic_weights: True
  normalize_loss: True
  loss_type: "l1"
  warm_up_step: 78

callbacks:
  model_checkpoint:
    monitor: "valid/total_loss"
    mode: min
    save_top_k: 5
    verbose: True
  early_stopping:
    monitor: "valid/total_loss"
    verbose: True
    mode: min
    patience: 10000

seed: 12345
test: True
